https://github.com/codebasics/deep-learning-keras-tf-tutorial/blob/master/6_gradient_descent/6_gradient_descent.ipynb

import numpy as np


y_predicted = np.array([1,1,0,0,1])
y_true = np.array([0.3,0.7,1,0,0.5])


np.mean(np.abs(y_predicted-y_true))


np.log([0.1])


epsilon = 1e-15


# which values are 0 we make it close to 0 but not 0
y_predicted_new = [max(i,epsilon) for i in y_predicted]


y_predicted_new


# which values are 1 we make it close to 1 but not 1
y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]


y_predicted_new = np.array(y_predicted_new)


# Log loss or binary cross entropy
-np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))


def log_loss(y_true, y_predicted):
    y_predicted_new = [max(i,epsilon) for i in y_predicted]
    y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]
    y_predicted_new = np.array(y_predicted_new)
    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))
    


log_loss(y_true, y_predicted)


# Mean square error
np.mean(np.square(y_predicted-y_true))


arr = np.array([5, 3, 1])


np.mean(np.square(arr))



